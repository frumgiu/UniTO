{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-04T15:13:31.722811Z",
     "start_time": "2023-06-04T15:13:26.711602Z"
    }
   },
   "outputs": [],
   "source": [
    "from esercizio import extract_sentences_with_verb, extract_subject_object_pairs, create_semantic_clusters, analyze_semantic_clusters, create_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "verb = ['see', 'sees', 'saw', 'seen', 'seeing']\n",
    "sentences = extract_sentences_with_verb(verb, 500)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T15:14:09.766734Z",
     "start_time": "2023-06-04T15:13:31.727371Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "109"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t, new_s = extract_subject_object_pairs(verb, sentences)\n",
    "len(t)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T15:14:18.134711Z",
     "start_time": "2023-06-04T15:14:09.772410Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "382"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_s)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T15:14:18.198155Z",
     "start_time": "2023-06-04T15:14:18.139855Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD -- DEP punct HEAD has\n",
      "WORD After DEP prep HEAD has\n",
      "WORD a DEP det HEAD controversy\n",
      "WORD long DEP amod HEAD controversy\n",
      "WORD , DEP punct HEAD controversy\n",
      "WORD hot DEP amod HEAD controversy\n",
      "WORD controversy DEP pobj HEAD After\n",
      "WORD , DEP punct HEAD has\n",
      "WORD Miller DEP compound HEAD County\n",
      "WORD County DEP nsubj HEAD has\n",
      "WORD has DEP ROOT HEAD has\n",
      "WORD a DEP det HEAD superintendent\n",
      "WORD new DEP amod HEAD superintendent\n",
      "WORD school DEP compound HEAD superintendent\n",
      "WORD superintendent DEP dobj HEAD has\n",
      "WORD , DEP punct HEAD has\n",
      "WORD elected DEP advcl HEAD has\n",
      "WORD , DEP punct HEAD elected\n",
      "WORD as DEP mark HEAD put\n",
      "WORD a DEP det HEAD policeman\n",
      "WORD policeman DEP nsubj HEAD put\n",
      "WORD put DEP advcl HEAD elected\n",
      "WORD it DEP dobj HEAD put\n",
      "WORD , DEP punct HEAD elected\n",
      "WORD in DEP prep HEAD elected\n",
      "WORD the DEP det HEAD election\n",
      "WORD ` DEP punct HEAD election\n",
      "WORD ` DEP punct HEAD election\n",
      "WORD coolest DEP amod HEAD election\n",
      "WORD election DEP pobj HEAD in\n",
      "WORD I DEP nsubj HEAD saw\n",
      "WORD ever DEP advmod HEAD saw\n",
      "WORD saw DEP relcl HEAD election\n",
      "WORD in DEP prep HEAD saw\n",
      "WORD this DEP det HEAD county\n",
      "WORD county DEP pobj HEAD in\n",
      "WORD '' DEP punct HEAD election\n",
      "WORD . DEP punct HEAD has\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "parser = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc = parser(new_s[2])\n",
    "for t in doc:\n",
    "    print('WORD', t, 'DEP', t.dep_, 'HEAD', t.head)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T15:22:22.580879Z",
     "start_time": "2023-06-04T15:22:21.677426Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT  --  root\n",
      "acl  --  clausal modifier of noun (adjectival clause)\n",
      "acomp  --  adjectival complement\n",
      "advcl  --  adverbial clause modifier\n",
      "advmod  --  adverbial modifier\n",
      "agent  --  agent\n",
      "amod  --  adjectival modifier\n",
      "appos  --  appositional modifier\n",
      "attr  --  attribute\n",
      "aux  --  auxiliary\n",
      "auxpass  --  auxiliary (passive)\n",
      "case  --  case marking\n",
      "cc  --  coordinating conjunction\n",
      "ccomp  --  clausal complement\n",
      "compound  --  compound\n",
      "conj  --  conjunct\n",
      "csubj  --  clausal subject\n",
      "csubjpass  --  clausal subject (passive)\n",
      "dative  --  dative\n",
      "dep  --  unclassified dependent\n",
      "det  --  determiner\n",
      "dobj  --  direct object\n",
      "expl  --  expletive\n",
      "intj  --  interjection\n",
      "mark  --  marker\n",
      "meta  --  meta modifier\n",
      "neg  --  negation modifier\n",
      "nmod  --  modifier of nominal\n",
      "npadvmod  --  noun phrase as adverbial modifier\n",
      "nsubj  --  nominal subject\n",
      "nsubjpass  --  nominal subject (passive)\n",
      "nummod  --  numeric modifier\n",
      "oprd  --  object predicate\n",
      "parataxis  --  parataxis\n",
      "pcomp  --  complement of preposition\n",
      "pobj  --  object of preposition\n",
      "poss  --  possession modifier\n",
      "preconj  --  pre-correlative conjunction\n",
      "predet  --  None\n",
      "prep  --  prepositional modifier\n",
      "prt  --  particle\n",
      "punct  --  punctuation\n",
      "quantmod  --  modifier of quantifier\n",
      "relcl  --  relative clause modifier\n",
      "xcomp  --  open clausal complement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giuliafrumento/PycharmProjects/TLNDiCaro/venv/lib/python3.8/site-packages/spacy/glossary.py:19: UserWarning: [W118] Term 'predet' not found in glossary. It may however be explained in documentation for the corpora used to train the language. Please check `nlp.meta[\"sources\"]` for any relevant links.\n",
      "  warnings.warn(Warnings.W118.format(term=term))\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "for label in nlp.get_pipe(\"parser\").labels:\n",
    "    print(label, \" -- \", spacy.explain(label))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T15:14:20.053496Z",
     "start_time": "2023-06-04T15:14:19.172374Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'spacy.tokens.token.Token' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m semantic_clusters \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_semantic_clusters\u001B[49m\u001B[43m(\u001B[49m\u001B[43mt\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/TLNDiCaro/EsercizioTre/esercizio.py:69\u001B[0m, in \u001B[0;36mcreate_semantic_clusters\u001B[0;34m(pairs)\u001B[0m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate_semantic_clusters\u001B[39m(pairs):\n\u001B[1;32m     67\u001B[0m     semantic_clusters \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m---> 69\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m subj, obj, sentence \u001B[38;5;129;01min\u001B[39;00m pairs:\n\u001B[1;32m     70\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m (subj, obj) \u001B[38;5;129;01min\u001B[39;00m semantic_clusters:\n\u001B[1;32m     71\u001B[0m             semantic_clusters[(subj, obj)][\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "\u001B[0;31mTypeError\u001B[0m: 'spacy.tokens.token.Token' object is not iterable"
     ]
    }
   ],
   "source": [
    "semantic_clusters = create_semantic_clusters(t)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T15:14:20.838155Z",
     "start_time": "2023-06-04T15:14:20.055661Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cluster_frequencies = analyze_semantic_clusters(semantic_clusters)\n",
    "create_image(cluster_frequencies)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
